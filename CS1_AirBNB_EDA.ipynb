{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations Required\n",
    "<br>\n",
    "!pip install geopandas\n",
    "<br>\n",
    "!pip3 install shapely==1.5.17.post1\n",
    "<br>\n",
    "!pip install geojsonio\n",
    "<br>\n",
    "!pip install langdetect\n",
    "<br>\n",
    "!pip install cufflinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import geojsonio\n",
    "import numpy as np\n",
    "import os\n",
    "import glob   \n",
    "import gc\n",
    "import time \n",
    "from collections import Counter\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from langdetect import detect\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "#https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef766\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "from bs4 import BeautifulSoup\n",
    "#Plotly Tools\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode()\n",
    "from plotly import tools\n",
    "import plotly.tools as tls\n",
    "init_notebook_mode(connected=True)\n",
    "#https://stackoverflow.com/questions/55132071/series-object-has-no-attribute-iplot/55132247\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Location Variables\n",
    "_DataFolderPath=\"Data\"\n",
    "_LocationName=\"Jersey_NJ\"\n",
    "_ListingCSV=\"listings\"\n",
    "_ReviewsCSV=\"reviews\"\n",
    "_NeighbourhoodsCSV=\"neighbourhoods.csv\"\n",
    "_CalendarCSV=\"calendar\"\n",
    "_NeighbourhoodsJson=\"neighbourhoods.geojson\"\n",
    "_LocationPath=_DataFolderPath +\"/\" + _LocationName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frames\n",
    "_DF_Listing= pd.DataFrame()\n",
    "_DF_Calendar=pd.DataFrame()\n",
    "_DF_Reviews=pd.DataFrame()\n",
    "_DF_Neighbourhoods= pd.read_csv( _LocationPath + \"/\" + _NeighbourhoodsCSV)\n",
    "_DF_Neighbourhoods_json = gpd.read_file( _LocationPath + \"/\" + _NeighbourhoodsJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/678236/how-to-get-the-filename-without-the-extension-from-a-path-in-python\n",
    "def file_base_name(file_name):\n",
    "    if '.' in file_name:\n",
    "        separator_index = file_name.index('.')\n",
    "        base_name = file_name[:separator_index]\n",
    "        return base_name\n",
    "    else:\n",
    "        return file_name\n",
    "\n",
    "def path_base_name(path):\n",
    "    file_name = os.path.basename(path)\n",
    "    return file_base_name(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/39100971/how-do-i-release-memory-used-by-a-pandas-dataframe\n",
    "def cleanDataFrame(objDf):\n",
    "    del objDf\n",
    "    gc.collect()\n",
    "    objDf=pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to clear Empty Spaces\n",
    "def replaceSpaces(text):\n",
    "    temp= str(text)\n",
    "    temp=text.strip()\n",
    "    temp=temp.replace('\\\\r', '')\n",
    "    temp=temp.replace('\\\\\"', '')\n",
    "    temp=temp.replace('\\\\n', '')\n",
    "    temp=temp.replace(' ', '_')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detects Language from Given text\n",
    "def detectLanguage(phrase):\n",
    "    try: \n",
    "        return detect(phrase)\n",
    "    except:\n",
    "        return 'na'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/60214194/error-in-reading-stock-data-datetimeproperties-object-has-no-attribute-week\n",
    "#https://docs.python.org/3/library/time.html\n",
    "def getWeekDayNumber(text):\n",
    "    return time.strptime(text, '%A').tm_wday\n",
    "\n",
    "def getMonthNumber(text):\n",
    "    return time.strptime(text, '%B').tm_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the results in 4 decemal points\n",
    "SAFE_DIV = 0.0001 \n",
    "STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    \n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    pattern = re.compile('\\W')\n",
    "    \n",
    "    if type(x) == type(''):\n",
    "        x = re.sub(pattern, ' ', x)\n",
    "    \n",
    "    \n",
    "    if type(x) == type(''):\n",
    "        x = porter.stem(x)\n",
    "        example1 = BeautifulSoup(x)\n",
    "        x = example1.get_text()\n",
    "               \n",
    "    \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_ANALYZER = SentimentIntensityAnalyzer()\n",
    "def getSentimentScore_Compound(text):\n",
    "    statement_polarity = SENTIMENT_ANALYZER.polarity_scores(text)\n",
    "    return statement_polarity['compound']\n",
    "\n",
    "def getSentimentScore_Compound(text):\n",
    "    statement_polarity = SENTIMENT_ANALYZER.polarity_scores(text)\n",
    "    return statement_polarity['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory\n",
    "#https://www.geeksforgeeks.org/python-os-scandir-method/\n",
    "totalFilesMergeCount=0\n",
    "totalCalendarsMereCount=0\n",
    "totalReviewsMergeCoun=0\n",
    "#Load Listing For Recent Quarter\n",
    "_DF_Listing = pd.read_csv(_LocationPath + \"/0/\" + _ListingCSV + \".csv.gz\" , compression='gzip')\n",
    "\n",
    "#Loop to fetch Reviews and Calendars for Past 1 Year based for Listing IDs of this quarter\n",
    "with os.scandir(_LocationPath) as objDir:\n",
    "    for entry in objDir:\n",
    "        if  entry.is_dir():\n",
    "            path = entry.path + \"/*.gz\" \n",
    "            files=glob.glob(path)\n",
    "            for file in files:\n",
    "                totalFilesMergeCount=totalFilesMergeCount+1\n",
    "                #print (\"Files Counter : \",totalFilesMergeCount)\n",
    "                fileName=path_base_name(file)\n",
    "                #print(fileName)\n",
    "                if fileName== _CalendarCSV:\n",
    "                    #print(path)\n",
    "                   # print(fileName)\n",
    "                    df = pd.read_csv(file, compression='gzip')\n",
    "                    _DF_Calendar=pd.concat([_DF_Calendar,df[df.listing_id.isin(_DF_Listing.id)]], ignore_index=True)\n",
    "                    totalCalendarsMereCount=totalCalendarsMereCount +df[df.listing_id.isin(_DF_Listing.id)].shape[0]\n",
    "                if fileName== _ReviewsCSV:\n",
    "                   # print(path)\n",
    "                   # print(fileName)\n",
    "                    df = pd.read_csv(file, compression='gzip')\n",
    "                    _DF_Reviews=pd.concat([_DF_Reviews,df[df.listing_id.isin(_DF_Listing.id)]], ignore_index=True)\n",
    "                    totalReviewsMergeCoun=totalReviewsMergeCoun+df[df.listing_id.isin(_DF_Listing.id)].shape[0]\n",
    "                \n",
    "objDir.close() \n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "print (\"Total Files Merged : \" ,  totalFilesMergeCount)\n",
    "print (\"Total Records Inserted for Calendar : \" , totalCalendarsMereCount)\n",
    "print (\"Total Records Inserted for Reviews : \", totalReviewsMergeCoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Listings : \", _DF_Listing.shape)\n",
    "print (\"Calendars : \", _DF_Calendar.shape)\n",
    "print (\"Reviews : \", _DF_Reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Information About Reviews DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "##########################################################################################\n",
    "#Trying to find duplicate reviews for same user in same listing for same date.\n",
    "#Not working\n",
    "#Need help\n",
    "#########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=_DF_Reviews[_DF_Reviews.duplicated(subset=['listing_id','reviewer_id','date'])] \n",
    "x.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "##########################################################################################\n",
    "#Trying to find duplicate reviews for same user in same listing for same date.\n",
    "#Not working\n",
    "#Need help\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Dara for Reviews Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews[(_DF_Reviews['id']==608103333) & (_DF_Reviews['listing_id']==42075992)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.listing_id[256353]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.comments[256353]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectLanguage(_DF_Reviews.comments[256353])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.comments[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectLanguage('혜빈\t숙소의 장점은 너무나도 많지만 몇가지 추려보자면...☺️\\n✔️맨해트보다 너무너무')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectLanguage('I strongly recommend you to stay this place. T..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_DF_Reviews['language_type'] = _DF_Reviews['comments'].apply(detectLanguage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews.loc[_DF_Reviews['language_type']!='en']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLanguagesCount=pd.DataFrame(_DF_Reviews.language_type.unique()).shape[0]\n",
    "print('Count/List of languages are used in comments -:', totalLanguagesCount)\n",
    "_DF_Reviews.language_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalReviewsCount=_DF_Reviews.shape[0]\n",
    "reviews_not_in_english=_DF_Reviews.loc[_DF_Reviews['language_type']!='en'].shape[0]\n",
    "print (\"Total Reviews : \", totalReviewsCount)\n",
    "print (\"Total Reviews Not English: \", reviews_not_in_english)\n",
    "percentage_diffLanguages=(reviews_not_in_english/totalReviewsCount)*100\n",
    "print (\"Percenatge of Differnt Languages : \",percentage_diffLanguages,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are removing comments which are non-english for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Reviews=_DF_Reviews[_DF_Reviews['language_type']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_DF_Reviews[\"comments_cleaned\"] = _DF_Reviews[\"comments\"].fillna(\"\").apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Sentiment Scores of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_DF_Reviews['Review_Score']=_DF_Reviews.comments_cleaned.apply(getSentimentScore_Compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "_DF_Reviews['Review_Len']=_DF_Reviews.comments_cleaned.apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add features Related to Reviews in Listings Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Empty Arrays Declaration for  Avg Review Scores, Review Count, Avg Review Lenght\n",
    "avg_review_score = []\n",
    "total_reviews = []\n",
    "avg_review_len=[]\n",
    "previous_reviewDate=[]\n",
    "latest_reviewDate=[]\n",
    "from tqdm import tqdm\n",
    " #https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas \n",
    "for index, row in tqdm( _DF_Listing.iterrows()):\n",
    "    temp_listingid=row['id']\n",
    "    filtered_reviews=_DF_Reviews[_DF_Reviews['listing_id']==temp_listingid] \n",
    "    df_sum=filtered_reviews.sum(axis = 0, skipna = True) \n",
    "    total_score= df_sum['Review_Score']\n",
    "    total_len=df_sum['Review_Len']\n",
    "    record_count=filtered_reviews.shape[0]\n",
    "    avg_review_score.append(total_score/record_count)\n",
    "    total_reviews.append(record_count)\n",
    "    avg_review_len.append(total_len/record_count)\n",
    "    latest_reviewDate.append(filtered_reviews.date.max())\n",
    "    previous_reviewDate.append(filtered_reviews.date.min())\n",
    "\n",
    "_DF_Listing['avg_review_score'] =avg_review_score\n",
    "_DF_Listing['total_reviews_count']=total_reviews\n",
    "_DF_Listing['avg_review_len'] =avg_review_len\n",
    "_DF_Listing['past_review_date'] =previous_reviewDate\n",
    "_DF_Listing['laste_review_date'] =latest_reviewDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Information About Calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar['price'].replace(regex=True, inplace=True, to_replace=r'[^0-9.\\-]',value=r'')\n",
    "_DF_Calendar['price'] = _DF_Calendar['price'].astype(float)\n",
    "_DF_Calendar['adjusted_price'].replace(regex=True, inplace=True, to_replace=r'[^0-9.\\-]',value=r'')\n",
    "_DF_Calendar['adjusted_price'] = _DF_Calendar['adjusted_price'].astype(float)\n",
    "#_DF_Calendar['available'] = _DF_Calendar['available'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have', _DF_Calendar.date.nunique(), 'days and', _DF_Calendar.listing_id.nunique(), 'unique listings in the calendar data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar['date'] = pd.to_datetime(_DF_Calendar['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar.date.min(), _DF_Calendar.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar.available.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar[_DF_Calendar.available=='t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar['available'] = _DF_Calendar.available.map(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar.available.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " _DF_Calendar[_DF_Calendar.listing_id==917065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar['day_of_week'] = _DF_Calendar.date.dt.day_name()\n",
    "_DF_Calendar['month'] = _DF_Calendar.date.dt.month_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Calendar['week_day_num']=_DF_Calendar['day_of_week'] .apply(getWeekDayNumber)\n",
    "_DF_Calendar['month_num']=_DF_Calendar['month'] .apply(getMonthNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempCalendar_g=_DF_Calendar.groupby('week_day_num')['available', 'price','adjusted_price','minimum_nights','maximum_nights'].mean().reset_index().rename(columns={'available':'avg_availablilty_rate','price' : 'avg_price','adjusted_price' : 'avg_adjusted_price','minimum_nights' :'avg_minimum_nights','maximum_nights':'avg_maximum_nights'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempCalendar_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAVR(val):\n",
    "    return (1-val)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/2468334/python-how-to-create-dynamic-and-expandable-dictionaries\n",
    "#https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression\n",
    "def updateDicForCalendarsListings(df_cal,groupByName):\n",
    "    colKeyName='month_num' if groupByName== 'm' else 'week_day_num'\n",
    "    keyRange= 12 if groupByName== 'm' else 7\n",
    "    dict_listings={}\n",
    "    monthCounter=0\n",
    "    for i in range(0,keyRange):\n",
    "        for name, values in df_cal.iteritems():\n",
    "            keyname=''\n",
    "            value=0\n",
    "            if name==colKeyName:\n",
    "                monthCounter=values[i]\n",
    "            else:\n",
    "                if groupByName=='m':\n",
    "                    keyName= calendar.month_abbr[monthCounter].lower() + '_' + name \n",
    "                else:\n",
    "                    keyName= calendar.day_abbr[monthCounter].lower() + '_' + name\n",
    "                value=values[i].astype(float)\n",
    "                value=round(value,2)\n",
    "                if keyName in dict_listings.keys():\n",
    "                    dict_listings[keyName].append(value)\n",
    "                else:\n",
    "                    dict_listings[keyName]=[]\n",
    "                    dict_listings[keyName].append(value)\n",
    "    return dict_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import calendar\n",
    "df_new= pd.DataFrame()\n",
    "from tqdm import tqdm\n",
    "for index, row in _DF_Listing.iterrows():\n",
    "    temp_listingid=row['id']\n",
    "    #Filter Calnders based on Listing ID\n",
    "    filtered_calendar=_DF_Calendar[_DF_Calendar['listing_id']==temp_listingid] \n",
    "   # print('filtered_calendar.shape')\n",
    "    #print(filtered_calendar.shape)\n",
    "    if filtered_calendar.shape[0] >0:\n",
    "        #Group by Weeks\n",
    "        tempCalendar_weekely=filtered_calendar.groupby('week_day_num')['available', 'price','adjusted_price','minimum_nights','maximum_nights'].mean().reset_index().rename(columns={'available':'avg_availablilty_rate','price' : 'avg_price','adjusted_price' : 'avg_adjusted_price','minimum_nights' :'avg_minimum_nights','maximum_nights':'avg_maximum_nights'})\n",
    "        tempCalendar_weekely['avg_availablilty_rate']= tempCalendar_weekely['avg_availablilty_rate'].apply(getAVR)\n",
    "        #Group by Months\n",
    "        tempCalendar_monthly=filtered_calendar.groupby('month_num')['available', 'price','adjusted_price','minimum_nights','maximum_nights'].mean().reset_index().rename(columns={'available':'avg_availablilty_rate','price' : 'avg_price','adjusted_price' : 'avg_adjusted_price','minimum_nights' :'avg_minimum_nights','maximum_nights':'avg_maximum_nights'}) \n",
    "        tempCalendar_weekely['avg_availablilty_rate']= tempCalendar_weekely['avg_availablilty_rate'].apply(getAVR)\n",
    "\n",
    "        #print('temp_listingid')\n",
    "       # print(temp_listingid)\n",
    "       # print('week')\n",
    "        #print(tempCalendar_weekely.shape)\n",
    "        dict_week=updateDicForCalendarsListings(tempCalendar_weekely,'w')\n",
    "       # print('month')\n",
    "        dict_month=updateDicForCalendarsListings(tempCalendar_monthly,'m')\n",
    "        dict_merge={**dict_week, **dict_month}\n",
    "        dict_merge['id']=[]\n",
    "        dict_merge['id'].append(temp_listingid)\n",
    "        #df_new= df_new.replace(dict_merge, regex=True, inplace=True)\n",
    "        df_new=df_new.append(dict_merge,ignore_index=True)\n",
    "        dict_merge.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/65465625/remove-square-brackets-from-all-rows-in-data-frame\n",
    "df_new = df_new.applymap(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.shanelynn.ie/merge-join-dataframes-python-pandas-index-1/\n",
    "_DF_Listing = pd.merge(_DF_Listing,\n",
    "                df_new,\n",
    "                 on='id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Information About NeighbourHood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Neighbourhoods.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Neighbourhoods.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Neighbourhoods.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_DF_Neighbourhoods_json.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = open(_LocationPath + \"/\" + _NeighbourhoodsJson).read()\n",
    "geojsonio.display(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA For Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We don't need following columns:\n",
    "'''\n",
    "1. listing_url -\" URL for Every Listing we dont need this\"\n",
    "2. scrape_id -: Related toData Collection\n",
    "3. last_scraped =\" Lasy date of data collected\"\n",
    "4. name of property\n",
    "5. picture_url\n",
    "6.host_url                                      \n",
    "7. c \n",
    "8.host_thumbnail_url\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA=_DF_Listing.drop(columns=['listing_url', 'scrape_id','last_scraped','name','picture_url','host_url','host_url','host_thumbnail_url'])\n",
    "_DF_Listing_EDA=_DF_Listing_EDA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/mistrzuniu1/tutorial-eda-feature-selection-regression\n",
    "total = _DF_Listing_EDA.isnull().sum().sort_values(ascending = False)\n",
    "percent = (_DF_Listing_EDA.isnull().sum()/_DF_Listing_EDA.isnull().count()*100).sort_values(ascending = False)\n",
    "missing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "pd.set_option('display.max_rows', 500)\n",
    "missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Columns which are 100 % Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA=_DF_Listing_EDA.drop(columns=['neighbourhood_group_cleansed', 'bathrooms','calendar_updated','license'])\n",
    "_DF_Listing_EDA=_DF_Listing_EDA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing and NLP for host_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.fillna({'host_about':'na'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.host_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_DF_Listing_EDA[\"host_about\"] = _DF_Listing_EDA[\"host_about\"].fillna(\"na\").apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.host_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "_DF_Listing_EDA['host_about_score']=_DF_Listing_EDA.host_about.apply(getSentimentScore_Compound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_about_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "_DF_Listing_EDA['host_about_len']=_DF_Listing_EDA.host_about.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_about_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_DF_Listing_EDA=_DF_Listing_EDA.drop(columns=['host_about'])\n",
    "_DF_Listing_EDA=_DF_Listing_EDA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP and Text Processing of  host_neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_DF_Listing_EDA[\"host_neighbourhoodd\"] = _DF_Listing_EDA[\"host_neighbourhood\"].fillna(\"\").apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[\"host_neighbourhoodd\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/60102928/pandas-fillna-only-numeric-int-or-float-columns\n",
    "numeric_columns = _DF_Listing_EDA.select_dtypes(include=['number']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill Null Value with 0 or na\n",
    "_DF_Listing_EDA.fillna({'reviews_per_month':0}, inplace=True)\n",
    "_DF_Listing_EDA.fillna({'neighborhood_overview':'na'}, inplace=True)\n",
    "_DF_Listing_EDA.fillna({'neighbourhood':'na'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill 0 to all NaN \n",
    "_DF_Listing_EDA[numeric_columns] = _DF_Listing_EDA[numeric_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.fillna('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/mistrzuniu1/tutorial-eda-feature-selection-regression\n",
    "total = _DF_Listing_EDA.isnull().sum().sort_values(ascending = False)\n",
    "percent = (_DF_Listing_EDA.isnull().sum()/_DF_Listing_EDA.isnull().count()*100).sort_values(ascending = False)\n",
    "missing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "pd.set_option('display.max_rows', 500)\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[_DF_Listing_EDA.id <=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert price to Float and Remove Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['price'].replace(regex=True, inplace=True, to_replace=r'[^0-9.\\-]',value=r'')\n",
    "_DF_Listing_EDA['price'] = _DF_Listing_EDA['price'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find if Price <=0 we will remove if price is <=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[_DF_Listing_EDA.price <=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['price'].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['price'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(_DF_Listing_EDA['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.distplot(_DF_Listing_EDA['price'], kde=False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will Do Univariate and Bi-Univariate Ananlysis for Each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features-:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[\"description\"] = _DF_Listing_EDA[\"description\"].fillna(\"\").apply(preprocess)\n",
    "description_corpus= _DF_Listing_EDA['description'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/tf-idf-model-for-page-ranking/\n",
    "#https://stackoverflow.com/questions/55547506/how-to-calculate-tfidf-score-from-a-column-of-dataframe-and-extract-words-with-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english')\n",
    "desc_tfidf=tfidf_vec.fit_transform(description_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_scores = pd.DataFrame(desc_tfidf.toarray(), columns=tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_above_threshold = df_desc_scores.max()[df_desc_scores.max() > 0.3].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/26097916/convert-pandas-series-to-dataframe\n",
    "df_desc_scores=pd.DataFrame({'features':tokens_above_threshold.index, 'score':tokens_above_threshold.values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.   Neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 .1  Neighborhood (Categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean neighbourhood Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_values = list(_DF_Listing_EDA['neighbourhood'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "\n",
    "neighbourhood_list = []\n",
    "for i in neighbourhood_values:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"NY,NJ,MH\"\n",
    "    if (str(i) != 'nan'):\n",
    "        #print(i)   \n",
    "        for j in i.split(','): # it will split it in three parts [\"NY\", \"NJ\", \"MH\"]\n",
    "            j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) \n",
    "            temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "            temp = temp.replace('&','_')\n",
    "            temp = temp.replace('UnitedStates','USA')\n",
    "            temp = temp.replace('NewJersey','NJ')\n",
    "            temp = temp.replace('NewJersey','NJ')\n",
    "        neighbourhood_list.append(temp.strip())\n",
    "\n",
    "_DF_Listing_EDA['neighbourhood'] = neighbourhood_list\n",
    "\n",
    "# count of all the words in corpus python: https://stackoverflow.com/a/22898595/4084039\n",
    "my_counter = Counter()\n",
    "for word in _DF_Listing_EDA['neighbourhood'].values:\n",
    "    my_counter.update(word.split())\n",
    "    \n",
    "neighbourhood_dict = dict(my_counter)\n",
    "sorted_neighbourhood_dict = dict(sorted(neighbourhood_dict.items(), key=lambda kv: kv[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2   Neighborhood_overview      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the Folloing for neighborhood_overview\n",
    "# 1.Text Preprocessing\n",
    "# 2. Calculating Sentiment Scores\n",
    "# 3. Calc Lenght of of Review\n",
    "#T4. Calc Word Count in Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_DF_Listing_EDA['neighborhood_overview'] = _DF_Listing_EDA[\"neighborhood_overview\"].fillna(\"\").apply(preprocess)\n",
    "_DF_Listing_EDA['neighborhood_overview_score']=_DF_Listing_EDA.neighborhood_overview.apply(getSentimentScore_Compound)\n",
    "_DF_Listing_EDA['neighborhood_overview_len']=_DF_Listing_EDA.neighborhood_overview.apply(len)\n",
    "_DF_Listing_EDA['neighborhood_overview_word_count'] = _DF_Listing_EDA['neighborhood_overview'].apply(lambda x: len(str(x).split()))\n",
    "_DF_Listing_EDA.drop(['neighborhood_overview'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_DF_Listing_EDA_nhood=_DF_Listing_EDA[['neighbourhood','price','neighborhood_overview_score','neighborhood_overview_len','neighborhood_overview_word_count','neighbourhood_cleansed','longitude','latitude']]\n",
    "\n",
    "_DF_Listing_EDA_nhood[['price','neighborhood_overview_score','neighborhood_overview_len','neighborhood_overview_word_count']] = scaler.fit_transform(_DF_Listing_EDA_nhood[['price','neighborhood_overview_score','neighborhood_overview_len','neighborhood_overview_word_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Three features added for neighbourhood_overview\n",
    "    # neighborhood_overview_score\n",
    "    #neighborhood_overview_len\n",
    "    #neighborhood_overview_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price'].mean().iplot(kind='bar',  xTitle='Neighbourhood', yTitle='Average Price')\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood_cleansed')['price'].mean().iplot(kind='bar',  xTitle='Neighbourhood', yTitle='Average Price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['neighbourhood', 'price']].pivot(columns='neighbourhood', values='price').iplot(kind='box')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['neighbourhood_cleansed', 'price']].pivot(columns='neighbourhood_cleansed', values='price').iplot(kind='box')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','neighborhood_overview_score'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['price','neighborhood_overview_score']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','neighborhood_overview_score',\n",
    "                                                                  'neighborhood_overview_len','neighborhood_overview_word_count'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['price','neighborhood_overview_score','neighborhood_overview_len','neighborhood_overview_word_count']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','neighborhood_overview_len','neighborhood_overview_word_count'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['price','neighborhood_overview_len','neighborhood_overview_word_count']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','neighborhood_overview_score',\n",
    "                                                                  'neighborhood_overview_len','neighborhood_overview_word_count'].mean().corr().iplot(kind='heatmap',colorscale=\"Blues\",title=\"Feature Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['price','neighbourhood','neighbourhood_cleansed','longitude','latitude']].corr().iplot(kind='heatmap',colorscale=\"Blues\",title=\"Feature Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "1. Maximum Listings are in Jersy City, NJ\n",
    "2. Highest Avg Price is in Hoboke : 207 USD\n",
    "3. AvgMinimm price is in jersy City, NJ: 40 USD\n",
    "4. Hoboken has very few listings as compare to  Jersy City\n",
    "5. Union City has Maximum Neighbourhood overview scores \n",
    "6. Jersy City,Hoboen,Bayonne Has Smillar neighbour Hood Scores \n",
    "7. Newyork has negtaive overviews with average price of 127 USD\n",
    "8. Over View Length, Overview Word Count are directly related to Avg price of Neighbour Hood\n",
    "10. Over Scores has no impact of score. Will rmove this coulmn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del _DF_Listing_EDA_nhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Review Scores of Listings :\n",
    "\n",
    "Will do Price Ananlysis and Multivarite Analysis with following features:\n",
    "\n",
    "    # avg_review_score                              \n",
    " \n",
    "    # total_reviews_count                             \n",
    " \n",
    "    # avg_review_len                                \n",
    " \n",
    "    # past_review_date                               \n",
    " \n",
    "    # laste_review_date                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['past_review_date'] = pd.to_datetime(_DF_Listing_EDA['past_review_date'])\n",
    "_DF_Listing_EDA['laste_review_date'] = pd.to_datetime(_DF_Listing_EDA['laste_review_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37840812/pandas-subtracting-two-date-columns-and-the-result-being-an-integer/46966942\n",
    "\n",
    "_DF_Listing_EDA['ReviewDate_Diff'] = (_DF_Listing_EDA['laste_review_date']-_DF_Listing_EDA['past_review_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.fillna({'ReviewDate_Diff':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood= _DF_Listing_EDA[['neighbourhood','avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff','host_id','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_DF_Listing_EDA_nhood[['avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff','price']]= scaler.fit_transform(_DF_Listing_EDA_nhood[['avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff','price']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Reviews Based on Neighbour Hoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','avg_review_score'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.groupby('neighbourhood')['price','avg_review_score'].mean().iplot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','total_reviews_count'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['price','total_reviews_count']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','avg_review_len'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['price','avg_review_len']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','ReviewDate_Diff'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood[['price','ReviewDate_Diff']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA_nhood.groupby('neighbourhood')['price','avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff'].mean().corr().iplot(kind='heatmap',colorscale=\"Blues\",title=\"Feature Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del  _DF_Listing_EDA_nhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Observations:\n",
    "\n",
    "1. Listings in Jersy City and Newyork Locations has Maximum Review  Scores\n",
    "2.  Listings in Hobokens has very less Review Scores\n",
    "3. All the listings hasve +ve review scores from 0.06 to 0.08\n",
    "4. Avergage Listing Scores has no impact on Neighbout Hood Listings \n",
    "5. Review Count and Review Date Diff has very much impact of Price of listings in Neighbour hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Scores Based On Every Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.describe()[['avg_review_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews= _DF_Listing_EDA[['id','avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff','host_id','price']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews[['avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff','price']] = scaler.fit_transform(df_Listing_EDA_reviews[['avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff','price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['price'].iplot(kind='hist', bins=100,  xTitle='Listing Price in $', yTitle='Count')\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews.groupby('id')['avg_review_score','price'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews.groupby('id')['price','total_reviews_count'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews.groupby('id')['price','avg_review_len'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews.groupby('id')['price','ReviewDate_Diff'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews.groupby('id')['price','avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Listing_EDA_reviews.groupby('id')['price','avg_review_score','total_reviews_count','avg_review_len','ReviewDate_Diff'].mean().corr().iplot(kind='heatmap',colorscale=\"Blues\",title=\"Feature Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_Listing_EDA_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "\n",
    "1. We took the top 100 and bottom 100 review points based on listings\n",
    "2. Pirce of Listings is very much corelated with Review Count and Review Date Difference\n",
    "3. Avg review score has very less impact on Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.   HOST\n",
    "      host_about_score                              \n",
    "      host_about_len                                  \n",
    "      host_neighbourhoodd  \n",
    "      host_location                                  \n",
    "      host_response_time                             \n",
    "      host_response_rate                             \n",
    "      host_acceptance_rate                           \n",
    "      host_is_superhost                              \n",
    "      host_picture_url                               \n",
    "      host_neighbourhood                             \n",
    "      host_listings_count                             \n",
    "      host_total_listings_count                       \n",
    "      host_verifications                             \n",
    "      host_has_profile_pic                           \n",
    "      host_identity_verified  \n",
    "      host_since "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_location']=_DF_Listing_EDA[\"host_location\"].fillna('na').apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_response_time']=_DF_Listing_EDA[\"host_response_time\"].fillna('na').apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_response_rate']=_DF_Listing_EDA[\"host_response_rate\"].fillna('na').apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_neighbourhood']=_DF_Listing_EDA[\"host_neighbourhood\"].fillna('na').apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_acceptance_rate']= _DF_Listing_EDA['host_acceptance_rate'].str.replace('%', '')\n",
    "_DF_Listing_EDA['host_acceptance_rate']=_DF_Listing_EDA['host_acceptance_rate'].astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_acceptance_rate']=_DF_Listing_EDA[\"host_acceptance_rate\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_acceptance_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_response_time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " _DF_Listing_EDA['host_response_rate']= _DF_Listing_EDA['host_response_rate'].str.replace('na', '0')   \n",
    "_DF_Listing_EDA['host_response_rate']= _DF_Listing_EDA['host_response_rate'].str.replace('percent', '')\n",
    "_DF_Listing_EDA['host_response_rate']=_DF_Listing_EDA['host_response_rate'].astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_is_superhost'] = _DF_Listing_EDA.host_is_superhost.map(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['Has_Profile_Pic'] = _DF_Listing_EDA.host_picture_url.map(lambda x: 1 if len (x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_identity_verified'] = _DF_Listing_EDA.host_identity_verified.map(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['Has_Profile_Pic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA=_DF_Listing_EDA.drop(columns=['host_picture_url'])\n",
    "_DF_Listing_EDA=_DF_Listing_EDA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_verifications_types']=_DF_Listing_EDA['host_verifications'].apply(lambda x: x.count(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_verifications_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA=_DF_Listing_EDA.drop(columns=['host_verifications'])\n",
    "_DF_Listing_EDA=_DF_Listing_EDA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[\"host_Since\"] = pd.to_datetime(_DF_Listing_EDA[\"host_since\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[\"host_Since\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/57011334/how-to-find-number-of-days-between-today-and-future-date/57013179\n",
    "_DF_Listing_EDA['host_age'] = ( pd.Timestamp('now')-_DF_Listing_EDA['host_Since']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA=_DF_Listing_EDA.drop(columns=['host_Since'])\n",
    "_DF_Listing_EDA=_DF_Listing_EDA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host=_DF_Listing_EDA[['host_id','host_name','host_about_score','host_about_len',\n",
    "                 'host_neighbourhoodd','host_location',\n",
    "                 'host_response_time','host_response_rate','host_acceptance_rate','host_is_superhost',\n",
    "                 'host_total_listings_count',\n",
    "                 'Has_Profile_Pic','host_has_profile_pic','host_verifications_types','host_age','price','id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['host_about_score','host_about_len','host_response_rate','host_acceptance_rate','host_total_listings_count','host_verifications_types','host_age','price']] = scaler.fit_transform(df_list_host[['host_about_score','host_about_len','host_response_rate','host_acceptance_rate','host_total_listings_count','host_verifications_types','host_age','price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_neighbourhoodd')['price'].mean().iplot(\n",
    "    kind='bar',\n",
    "    xTitle='Host Neighbourhood',\n",
    "    linecolor='black',\n",
    "    yTitle='Avg Price',\n",
    "    title='Host Neighbour Hood Vs Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_location')['price'].mean().iplot(\n",
    "    kind='bar',\n",
    "    xTitle='Host Location',\n",
    "    linecolor='black',\n",
    "    yTitle='Price',\n",
    "    title='Host Location vs Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['host_about_score','price'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['price','host_about_score']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['host_about_len','price'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['price','host_about_len']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['host_about_score','host_about_len','price'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['price','host_response_rate'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['price','host_response_rate']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['price','host_acceptance_rate'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['price','host_acceptance_rate']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_list_host['neighbourhood']= _DF_Listing_EDA['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['price','host_total_listings_count'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['price','host_total_listings_count']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['price','host_age'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['price','host_age']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby('host_name')['price','host_verifications_types'].mean().iplot(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['price','host_verifications_types']].iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby(['host_is_superhost','neighbourhood'])['price'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby(['host_is_superhost','neighbourhood'])['price'].mean().iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby(['host_has_profile_pic','neighbourhood'])['price'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby(['host_has_profile_pic','neighbourhood'])['price'].mean().iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host.groupby(['Has_Profile_Pic','neighbourhood'])['price'].mean().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list_host.groupby(['Has_Profile_Pic','neighbourhood'])['price'].mean().iplot(kind = 'scatter' , mode = 'markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_host[['host_about_score','host_about_len','host_response_rate','host_acceptance_rate','host_total_listings_count','host_verifications_types','host_age','Has_Profile_Pic','host_has_profile_pic','host_is_superhost','price']].corr().iplot(kind='heatmap',colorscale=\"Blues\",title=\"Feature Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_list_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.neighbourhood_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing for Room Types\n",
    "_DF_Listing_EDA.room_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Empty Arrays Declaration for  room_type\n",
    "preprocessed_room_type = []\n",
    "from tqdm import tqdm\n",
    " #https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas \n",
    "for index, row in tqdm( _DF_Listing_EDA.iterrows()):\n",
    "    temprtype=replaceSpaces(row['room_type'])\n",
    "    preprocessed_room_type.append(temprtype.lower().strip())\n",
    "\n",
    "_DF_Listing_EDA['clean_room_type'] = preprocessed_room_type\n",
    "_DF_Listing_EDA.drop(['room_type'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.clean_neighbourhood.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.clean_room_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.amenities.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_values = list(_DF_Listing_EDA['amenities'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "\n",
    "amenities_list = []\n",
    "for i in amenities_values:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"NY,NJ,MH\"\n",
    "    if (str(i) != 'nan'):\n",
    "        #print(i)   \n",
    "        for j in i.split(','): # it will split it in three parts [\"NY\", \"NJ\", \"MH\"]\n",
    "            j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) \n",
    "            temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "            temp = temp.replace('&','_')\n",
    "        amenities_list.append(temp.strip())\n",
    "\n",
    "_DF_Listing_EDA['clean_amenities'] = amenities_list\n",
    "#_DF_Listing_EDA.drop(['amenities'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# count of all the words in corpus python: https://stackoverflow.com/a/22898595/4084039\n",
    "my_counter = Counter()\n",
    "for word in _DF_Listing_EDA['clean_amenities'].values:\n",
    "    my_counter.update(word.split())\n",
    "    \n",
    "amenities_dict = dict(my_counter)\n",
    "sorted_amenities_dict = dict(sorted(amenities_dict.items(), key=lambda kv: kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_amenities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.clean_amenities.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['neighborhood_overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA['property_type'] = _DF_Listing_EDA[\"property_type\"].fillna(\"\").apply(preprocess)\n",
    "_DF_Listing_EDA.property_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will Do Analysis of Price with Each Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.hist(bins=50, figsize=(30,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Room Type  AND PROPERTY TYPE Analysis for Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.property_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.clean_room_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import hist\n",
    "\n",
    "hist(_DF_Listing_EDA.clean_room_type, weights=_DF_Listing_EDA.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(_DF_Listing_EDA['clean_room_type'], palette=\"plasma\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.title('Room Trype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_room_groups= _DF_Listing_EDA.groupby('clean_room_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_by_room=df_room_groups.agg(mean_Price=('price',np.mean),max_price=('price',np.max),min_price=('price',np.min),medain_price=('price',np.median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_by_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_by_room.plot(kind=\"bar\",figsize = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x= _DF_Listing_EDA['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "title = 'Avg Price per Room Type'\n",
    "result = _DF_Listing_EDA.groupby([\"clean_room_type\"])['price'].aggregate(np.mean).reset_index().sort_values('price')\n",
    "\n",
    "a4_dims = (11, 8)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "sns.barplot(x='clean_room_type', y=\"price\", ax=ax,\n",
    "            data=_DF_Listing_EDA, order=result['clean_room_type'])\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[_DF_Listing_EDA.price>=2000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[_DF_Listing_EDA.price>=1350].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA[_DF_Listing_EDA.price>=239].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(x=\"clean_room_type\", y=\"price\", data= _DF_Listing_EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propertytype_DF = _DF_Listing_EDA.groupby('property_type').id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propertytype_DF.plot(kind = 'barh' , figsize = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_price = _DF_Listing_EDA\\\n",
    "                    .groupby('property_type')['price']\\\n",
    "                    .median()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .index\n",
    "sns.boxplot(y='price', x='property_type', data=_DF_Listing_EDA, order=sort_price)\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.figure(figsize=(100, 50))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(x=\"property_type\", y=\"price\", data= _DF_Listing_EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomProperty_DF = _DF_Listing_EDA.groupby(['property_type','clean_room_type']).price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomProperty_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomProperty_DF.plot(kind='barh',figsize = (12,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation : (Room Type)</b> </br>\n",
    "1. There are four types of room availabe. </br>\n",
    "2. Maximum listings are available for entire_home/apt. </br>\n",
    "3. Listings with private_room are almost half of the entire_home/apt. </br>\n",
    "4. Listing with htel room and share room are very less and almost similar in count. </br>\n",
    "5. Max Price USD 2000 is for shared room and Entire home looks like an oulier  </br>\n",
    "6. Avg price for for Entire Home is 175 whereas Max is 2000. </br>\n",
    "7. Avg Price for hotel room is 89  Max is 239. </br>\n",
    "8. Avg Price for Private Room is 68 and Max is 1350. 1350 also looks like outlier </br>\n",
    "9. Shared rooms are more costly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 .Neighbour Hood Analysis for Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.clean_neighbourhood.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nType_DF=_DF_Listing_EDA.groupby('clean_neighbourhood').id.count()\n",
    "nType_DF.plot(kind = 'barh' , figsize = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_by_neighbourhood=_DF_Listing_EDA.groupby('clean_neighbourhood').agg(mean_Price=('price',np.mean),max_price=('price',np.max)\n",
    "                                                   ,min_price=\n",
    "                                     ('price',np.min),medain_price=('price',np.median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_by_neighbourhood.plot(kind = 'barh' , figsize = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neighbour Hood Based Overview and Count\n",
    "\n",
    "'''\n",
    "_DF_Listing['avg_review_score'] =avg_review_score\n",
    "_DF_Listing['total_reviews_count']=total_reviews\n",
    "_DF_Listing['avg_review_len'] =avg_review_len\n",
    "_DF_Listing['past_review_date'] =previous_reviewDate\n",
    "_DF_Listing['laste_review_date'] =latest_reviewDate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neighbouthood_overviews= _DF_Listing_EDA.groupby('clean_neighbourhood')['neighborhood_overview_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neighbouthood_overviews.plot(kind = 'barh' , figsize = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_index = list(_DF_Listing_EDA['clean_neighbourhood'].unique())\n",
    "grouped_df = _DF_Listing_EDA.groupby(\n",
    "'clean_neighbourhood')['neighborhood_overview_score','price'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(_DF_Listing_EDA['neighborhood_overview_score'], _DF_Listing_EDA['price'])\n",
    "plt.show() # Depending on whether you use IPython or interactive mode, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "sns.boxplot(x=\"clean_neighbourhood\", y=\"reviews_per_month\", data= _DF_Listing_Filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "sns.boxplot(x=\"clean_neighbourhood\", y=\"calculated_host_listings_count\", data= _DF_Listing_Filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation: </b> </br>\n",
    "\n",
    "1. Maximum Listings are in Neighbour hood of Jersey City, New Jersey\n",
    "2. Listings around New York, UnitedStates are very less\n",
    "3. Second Highest count of listinsg has not mentioned neighbour hood.\n",
    "4. Maxminum Avg prices are near NY and NJ\n",
    "5. Maximum Reviews are found in Jersey City, New Jersey\n",
    "6. Hoboken NJ  is most costly Neighbour hood\n",
    "7. NorthBergen NJ has very less prices than oher areas\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Based on Hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Hosts with maximum listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_host_20=_DF_Listing_Filtered.host_id.value_counts().head(20)\n",
    "max_host_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum listings hosted by a single host are 117.\n",
    "#Lets Verify them with  host listing count columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_DF_Listing_Filtered.host_id.value_counts()[:30].plot(kind='bar',x='Host ID', y='Count',ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_host_df=pd.DataFrame(max_host_20)\n",
    "top_host_df.reset_index(inplace=True)\n",
    "top_host_df.rename(columns={'index':'Host_ID', 'host_id':'P_Count'}, inplace=True)\n",
    "top_host_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_1=sns.barplot(x=\"Host_ID\", y=\"P_Count\", data=top_host_df,\n",
    "                 palette='Blues_d')\n",
    "viz_1.set_title('Hosts with the most listings in NYC')\n",
    "viz_1.set_ylabel('Count of listings')\n",
    "viz_1.set_xlabel('Host IDs')\n",
    "viz_1.set_xticklabels(viz_1.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>After first 10 Hosts rest has almost same distribution.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupBy_Host=_DF_Listing_Filtered.groupby('host_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupBy_Host.agg(mean_Price=('price',np.mean),max_price=('price',np.max)\n",
    "                                                   ,min_price=\n",
    "                                     ('price',np.min),medain_price=('price',np.median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Hosts based on Maximum Reviews Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_host_max_reviews = _DF_Listing_Filtered.groupby('host_id').agg({'number_of_reviews': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_host_max_reviews.sort_values('number_of_reviews', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "title = 'Correlation matrix of numerical variables'\n",
    "sns.heatmap(_DF_Listing_Filtered.corr(), square=True, cmap='RdYlGn')\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://www.kaggle.com/biphili/hospitality-in-era-of-airbnb\n",
    "title = 'Neighbourhood Group Location'\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(_DF_Listing_Filtered.longitude,_DF_Listing_Filtered.latitude,\n",
    "                hue=_DF_Listing_Filtered.clean_neighbourhood).set_title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Room type location per Neighbourhood Group'\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(_DF_Listing_Filtered.longitude,_DF_Listing_Filtered.latitude,\n",
    "                hue=_DF_Listing_Filtered.clean_room_type).set_title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Room type location per Neighbourhood Group'\n",
    "sns.catplot(x='clean_room_type', kind=\"count\", hue=\"clean_neighbourhood\", data=_DF_Listing_Filtered);\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ananlysis Based On Min and Max Nights Spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_Filtered.describe()['minimum_nights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_Filtered.describe()['maximum_nights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_by_neighbourhood_nights_min=df_neighbouthood_groups.agg(mean_nights=('minimum_nights',np.mean),max_nights=('minimum_nights',np.max)\n",
    "                                                   ,min_reviews=\n",
    "                                     ('minimum_nights',np.min),medain_nights=('minimum_nights',np.median),count_nights=('minimum_nights',np.sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_by_neighbourhood_nights_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_reviews_by_neighbourhood_nights_max=df_neighbouthood_groups.agg(mean_nights=('maximum_nights',np.mean),max_nights=('maximum_nights',np.max)\n",
    "                                                   ,min_reviews=\n",
    "                                     ('maximum_nights',np.min),medain_nights=('maximum_nights',np.median),count_nights=('maximum_nights',np.sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_reviews_by_neighbourhood_nights_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sentiments Neighbour Hood Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for_sentiment = 'a person is a person no matter how small dr seuss i teach the smallest students with the biggest enthusiasm \\\n",
    "for learning my students learn in many different ways using all of our senses and multiple intelligences i use a wide range\\\n",
    "of techniques to help all my students succeed students in my class come from a variety of different backgrounds which makes\\\n",
    "for wonderful sharing of experiences and cultures including native americans our school is a caring community of successful \\\n",
    "learners which can be seen through collaborative student project based learning in and out of the classroom kindergarteners \\\n",
    "in my class love to work with hands on materials and have many different opportunities to practice a skill before it is\\\n",
    "mastered having the social skills to work cooperatively with friends is a crucial aspect of the kindergarten curriculum\\\n",
    "montana is the perfect place to learn about agriculture and nutrition my students love to role play in our pretend kitchen\\\n",
    "in the early childhood classroom i have had several kids ask me can we try cooking with real food i will take their idea \\\n",
    "and create common core cooking lessons where we learn important math and writing concepts while cooking delicious healthy \\\n",
    "food for snack time my students will have a grounded appreciation for the work that went into making the food and knowledge \\\n",
    "of where the ingredients came from as well as how it is healthy for their bodies this project would expand our learning of \\\n",
    "nutrition and agricultural cooking recipes by having us peel our own apples to make homemade applesauce make our own bread \\\n",
    "and mix up healthy plants from our classroom garden in the spring we will also create our own cookbooks to be printed and \\\n",
    "shared with families students will gain math and literature skills as well as a life long enjoyment for healthy cooking \\\n",
    "nannan'\n",
    "ss = sid.polarity_scores(for_sentiment)\n",
    "\n",
    "for k in ss:\n",
    "    print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "\n",
    "# we can use these 4 things as features/attributes (neg, neu, pos, compound)\n",
    "# neg: 0.0, neu: 0.753, pos: 0.247, compound: 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f\n",
    "clean_neighborhood_overviews=  _DF_Listing_Filtered['clean_neighborhood_overview']\n",
    "clean_neighborhood_overviews_sentiments = []\n",
    "for text in tqdm(clean_neighborhood_overviews):\n",
    "    res = sid.polarity_scores(text)\n",
    "    clean_neighborhood_overviews_sentiments.append(res['compound']) #Considering compound as a criteria.\n",
    "\n",
    "_DF_Listing_Filtered['clean_neighborhood_overview_sentiment'] = clean_neighborhood_overviews_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_DF_Listing_Filtered['clean_neighborhood_overview_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_Filtered.describe()['clean_neighborhood_overview_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "title = 'Avg Sentiments of Host per Room Type'\n",
    "result = _DF_Listing_Filtered.groupby([\"clean_room_type\"])['clean_neighborhood_overview_sentiment'].aggregate(np.mean).reset_index().sort_values('clean_neighborhood_overview_sentiment')\n",
    "\n",
    "a4_dims = (11, 8)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "sns.barplot(x='clean_room_type', y=\"clean_neighborhood_overview_sentiment\", ax=ax,\n",
    "            data=_DF_Listing_Filtered, order=result['clean_room_type'])\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "title = 'Avg Sentiments of Host per Neighbour Hood '\n",
    "result = _DF_Listing_Filtered.groupby([\"clean_neighbourhood\"])['clean_neighborhood_overview_sentiment'].aggregate(np.mean).reset_index().sort_values('clean_neighborhood_overview_sentiment')\n",
    "\n",
    "a4_dims = (25, 15)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "sns.barplot(x='clean_neighbourhood', y=\"clean_neighborhood_overview_sentiment\", ax=ax,\n",
    "            data=_DF_Listing_Filtered, order=result['clean_neighbourhood'])\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn_max_reviews = _DF_Listing_Filtered.groupby('clean_neighbourhood').agg({'clean_neighborhood_overview_sentiment': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn_max_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DF_Listing_EDA.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
